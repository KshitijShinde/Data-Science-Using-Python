{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1S63toZGjv4OQx5KIbYlHVEGaG0NPq6kw",
      "authorship_tag": "ABX9TyMUGUyNlZGcVG04bZ+ZP5pR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KshitijShinde/Data-Science-Using-Python/blob/main/12_Bagging_And_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvJZJU9UYQ6Q",
        "outputId": "c4046085-70f9-4651-b274-5b9bc8fbf958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            7.4              0.70         0.00             1.9      0.076   \n",
            "1            7.8              0.88         0.00             2.6      0.098   \n",
            "2            7.8              0.76         0.04             2.3      0.092   \n",
            "3           11.2              0.28         0.56             1.9      0.075   \n",
            "4            7.4              0.70         0.00             1.9      0.076   \n",
            "\n",
            "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
            "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
            "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
            "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "\n",
            "   alcohol  quality  \n",
            "0      9.4        5  \n",
            "1      9.8        5  \n",
            "2      9.8        5  \n",
            "3      9.8        6  \n",
            "4      9.4        5  \n",
            "Accuracy of the Random Forest Model on Wine Quality: 80.21%\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine Quality dataset (assuming it's downloaded as 'winequality-red.csv')\n",
        "# If using the URL, make sure it's accessible\n",
        "data = pd.read_csv('/content/drive/MyDrive/dataset/winequality-red.csv', delimiter=';')\n",
        "\n",
        "# Inspect the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Features (X) and labels (y)\n",
        "X = data.drop('quality', axis=1)  # Features (all columns except 'quality')\n",
        "y = data['quality']  # Labels (the 'quality' column)\n",
        "\n",
        "# Convert 'quality' to binary classification (optional)\n",
        "# Label wines with quality >= 6 as 'good' (1), others as 'bad' (0)\n",
        "y = (y >= 6).astype(int)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier (which uses bagging internally)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the Random Forest Model on Wine Quality: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine Quality dataset (assuming it's downloaded as 'winequality-red.csv')\n",
        "data = pd.read_csv('/content/drive/MyDrive/dataset/winequality-red.csv', delimiter=';')\n",
        "\n",
        "# Inspect the first few rows of the dataset\n",
        "print(\"Full dataset:\\n\", data.head())\n",
        "\n",
        "# Subset 1: First 100 rows\n",
        "subset1 = data.iloc[:100]\n",
        "# Subset 2: Next 100 rows (rows 101 to 200)\n",
        "subset2 = data.iloc[100:200]\n",
        "# Subset 3: Next 100 rows (rows 201 to 300)\n",
        "subset3 = data.iloc[200:300]\n",
        "\n",
        "# Features and labels for Subset 1\n",
        "X1 = subset1.drop('quality', axis=1)\n",
        "y1 = subset1['quality']\n",
        "y1 = (y1 >= 6).astype(int)  # Convert to binary classification\n",
        "\n",
        "# Features and labels for Subset 2\n",
        "X2 = subset2.drop('quality', axis=1)\n",
        "y2 = subset2['quality']\n",
        "y2 = (y2 >= 6).astype(int)  # Convert to binary classification\n",
        "\n",
        "# Features and labels for Subset 3\n",
        "X3 = subset3.drop('quality', axis=1)\n",
        "y3 = subset3['quality']\n",
        "y3 = (y3 >= 6).astype(int)  # Convert to binary classification\n",
        "\n",
        "# Function to train and test the Bagging Classifier\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
        "    # Initialize the Bagging Classifier with Decision Trees as the base estimator\n",
        "    bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train the Bagging Classifier\n",
        "    bagging.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = bagging.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on Subset 1\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "accuracy1 = train_and_evaluate(X_train1, X_test1, y_train1, y_test1)\n",
        "\n",
        "# Evaluate on Subset 2\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
        "accuracy2 = train_and_evaluate(X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "# Evaluate on Subset 3\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
        "accuracy3 = train_and_evaluate(X_train3, X_test3, y_train3, y_test3)\n",
        "\n",
        "# Output the accuracies for each subset\n",
        "print(f\"Accuracy on Subset 1: {accuracy1 * 100:.2f}%\")\n",
        "print(f\"Accuracy on Subset 2: {accuracy2 * 100:.2f}%\")\n",
        "print(f\"Accuracy on Subset 3: {accuracy3 * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NahVPorPZJHa",
        "outputId": "300e1531-d7e9-47ed-f58b-ca4703971c44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset:\n",
            "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            7.4              0.70         0.00             1.9      0.076   \n",
            "1            7.8              0.88         0.00             2.6      0.098   \n",
            "2            7.8              0.76         0.04             2.3      0.092   \n",
            "3           11.2              0.28         0.56             1.9      0.075   \n",
            "4            7.4              0.70         0.00             1.9      0.076   \n",
            "\n",
            "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
            "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
            "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
            "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "\n",
            "   alcohol  quality  \n",
            "0      9.4        5  \n",
            "1      9.8        5  \n",
            "2      9.8        5  \n",
            "3      9.8        6  \n",
            "4      9.4        5  \n",
            "Accuracy on Subset 1: 75.00%\n",
            "Accuracy on Subset 2: 85.00%\n",
            "Accuracy on Subset 3: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine Quality dataset (assuming it's downloaded as 'winequality-red.csv')\n",
        "data = pd.read_csv('/content/drive/MyDrive/dataset/winequality-red.csv', delimiter=';')\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "random_seed = 42\n",
        "\n",
        "# Ensure we only select indices up to 300\n",
        "max_index = 300\n",
        "\n",
        "# Randomly select rows for subsets using indices up to 300\n",
        "subset1_indices = np.random.choice(range(max_index), size=100, replace=False)  # Random 100 indices\n",
        "subset2_indices = np.random.choice(range(max_index), size=100, replace=False)  # Random 100 indices\n",
        "subset3_indices = np.random.choice(range(max_index), size=100, replace=False)  # Random 100 indices\n",
        "\n",
        "# Create 3 random subsets by selecting rows from the dataset based on the random indices\n",
        "subset1 = data.iloc[subset1_indices]\n",
        "subset2 = data.iloc[subset2_indices]\n",
        "subset3 = data.iloc[subset3_indices]\n",
        "\n",
        "# Features and labels for Subset 1\n",
        "X1 = subset1.drop('quality', axis=1)\n",
        "y1 = subset1['quality']\n",
        "y1 = (y1 >= 6).astype(int)  # Convert to binary classification\n",
        "\n",
        "# Features and labels for Subset 2\n",
        "X2 = subset2.drop('quality', axis=1)\n",
        "y2 = subset2['quality']\n",
        "y2 = (y2 >= 6).astype(int)  # Convert to binary classification\n",
        "\n",
        "# Features and labels for Subset 3\n",
        "X3 = subset3.drop('quality', axis=1)\n",
        "y3 = subset3['quality']\n",
        "y3 = (y3 >= 6).astype(int)  # Convert to binary classification\n",
        "\n",
        "# Function to train and test the Bagging Classifier\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
        "    # Initialize the Bagging Classifier with Decision Trees as the base estimator\n",
        "    bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train the Bagging Classifier\n",
        "    bagging.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = bagging.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on Subset 1\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=random_seed)\n",
        "accuracy1 = train_and_evaluate(X_train1, X_test1, y_train1, y_test1)\n",
        "\n",
        "# Evaluate on Subset 2\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=random_seed)\n",
        "accuracy2 = train_and_evaluate(X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "# Evaluate on Subset 3\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=random_seed)\n",
        "accuracy3 = train_and_evaluate(X_train3, X_test3, y_train3, y_test3)\n",
        "\n",
        "# Output the accuracies for each subset\n",
        "print(f\"Accuracy on Subset 1 (Random, max index 300): {accuracy1 * 100:.2f}%\")\n",
        "print(f\"Accuracy on Subset 2 (Random, max index 300): {accuracy2 * 100:.2f}%\")\n",
        "print(f\"Accuracy on Subset 3 (Random, max index 300): {accuracy3 * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRH0MTYgZkiB",
        "outputId": "03ff4dfe-f005-4e1f-97ec-ac4e25a6e62b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Subset 1 (Random, max index 300): 85.00%\n",
            "Accuracy on Subset 2 (Random, max index 300): 70.00%\n",
            "Accuracy on Subset 3 (Random, max index 300): 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Function to train and test the Boosting Classifier\n",
        "def train_and_evaluate_boosting(X_train, X_test, y_train, y_test):\n",
        "    # Initialize the Boosting Classifier\n",
        "    boosting = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train the Boosting Classifier\n",
        "    boosting.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = boosting.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate Boosting on Subset 1\n",
        "boosting_accuracy1 = train_and_evaluate_boosting(X_train1, X_test1, y_train1, y_test1)\n",
        "\n",
        "# Evaluate Boosting on Subset 2\n",
        "boosting_accuracy2 = train_and_evaluate_boosting(X_train2, X_test2, y_train2, y_test2)\n",
        "\n",
        "# Evaluate Boosting on Subset 3\n",
        "boosting_accuracy3 = train_and_evaluate_boosting(X_train3, X_test3, y_train3, y_test3)\n",
        "\n",
        "# Output the accuracies for Boosting\n",
        "print(f\"Boosting Accuracy on Subset 1 (Random, max index 300): {boosting_accuracy1 * 100:.2f}%\")\n",
        "print(f\"Boosting Accuracy on Subset 2 (Random, max index 300): {boosting_accuracy2 * 100:.2f}%\")\n",
        "print(f\"Boosting Accuracy on Subset 3 (Random, max index 300): {boosting_accuracy3 * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UluKx2wErFS7",
        "outputId": "bcbedace-b0ba-46d4-c787-a71421c42ec5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boosting Accuracy on Subset 1 (Random, max index 300): 65.00%\n",
            "Boosting Accuracy on Subset 2 (Random, max index 300): 75.00%\n",
            "Boosting Accuracy on Subset 3 (Random, max index 300): 90.00%\n"
          ]
        }
      ]
    }
  ]
}